{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords as stopwords_scratch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tutorial\\week9\\godrick\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Tutorial\\week9\\godrick\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Tutorial\\week9\\godrick\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\Tutorial\\week9\\godrick\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 0.22.2.post1 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_bow = pickle.load(open(\"./model/feature-bow.p\",'rb'))\n",
    "model_nb = pickle.load(open('./model/model-nb.p', 'rb'))\n",
    "model_nn = pickle.load(open('./model/model-nn.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = stopwords_scratch.words('indonesian')\n",
    "\n",
    "list_stopwords_en = stopwords_scratch.words('english')\n",
    "\n",
    "list_stopwords.extend(list_stopwords_en)\n",
    "\n",
    "# Tambah daftar stopword\n",
    "list_stopwords.extend(['apa', 'yang', 'ini', 'itu', 'haha', 'hehe', 'dong', 'mah','nih', 'kok', 'ya', 'yg', 'si', 'kan', 'gak', 'deh', 'tuh','ga', 'aja', 'yuk', 'dah', 'ngga', 'engga', 'yah', 'gak', 'nya', 'kali'])\n",
    "\n",
    "# Buat DataFrame dari list stopwords\n",
    "stopwords_df = pd.DataFrame(list_stopwords, columns=['stopword'])\n",
    "\n",
    "# Simpan DataFrame sebagai CSV\n",
    "stopwords_df.to_csv('stopword_filter.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gw yang niat edukasi penyakit yang langka aja ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku pernah dikatain \"ih gay gak suka cewek, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trending nya joget2 atau lucu2 sama kayak di n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kalau bikin konten gimmick menurut lu gimana. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mau heran tapi lupa ini di negeri indoðŸ˜‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0  Gw yang niat edukasi penyakit yang langka aja ...\n",
       "1  aku pernah dikatain \"ih gay gak suka cewek, pa...\n",
       "2  trending nya joget2 atau lucu2 sama kayak di n...\n",
       "3  kalau bikin konten gimmick menurut lu gimana. ...\n",
       "4            Mau heran tapi lupa ini di negeri indoðŸ˜‚"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/commentsvid.csv')\n",
    "stop_words = pd.read_csv('./data/stopword_filter.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1361 entries, 0 to 1360\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   comment  1360 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 10.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1361 entries, 0 to 1360\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   comment  1360 non-null   string\n",
      "dtypes: string(1)\n",
      "memory usage: 10.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['comment'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Stemmer for Bahasa Indonesia\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(comment):\n",
    "    # 1. Hapus emoji\n",
    "    comment = emoji.replace_emoji(comment, replace=\"\")\n",
    "    \n",
    "    # 2. Hapus mention (@username)\n",
    "    comment = re.sub(r'@\\w+', '', comment)\n",
    "    \n",
    "    # 3. Hapus nama orang (asumsi nama dengan kapitalisasi huruf besar pertama)\n",
    "    comment = re.sub(r'\\b[A-Z][a-z]*\\b', '', comment)\n",
    "    \n",
    "    # 4. Hapus URL dan karakter non-alfabet (angka, tanda baca, simbol)\n",
    "    comment = re.sub(r'http\\S+|www\\S+|https\\S+|[^a-zA-Z\\s]', '', comment)\n",
    "    \n",
    "    # 5. Konversi ke lowercase\n",
    "    comment = comment.lower()\n",
    "    \n",
    "    # 6. Hapus karakter berulang (misalnya \"soooo\" menjadi \"soo\")\n",
    "    comment = re.sub(r'(.)\\1+', r'\\1\\1', comment)\n",
    "    \n",
    "    # 7. Hapus spasi berlebih\n",
    "    comment = re.sub(r'\\s+', ' ', comment).strip()\n",
    "    \n",
    "    tokens = word_tokenize(comment)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Remove very short words (less than 2 characters)\n",
    "    tokens = [word for word in tokens if len(word) > 2]\n",
    "    # Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  \\\n",
      "0  Gw yang niat edukasi penyakit yang langka aja ...   \n",
      "1  aku pernah dikatain \"ih gay gak suka cewek, pa...   \n",
      "2  trending nya joget2 atau lucu2 sama kayak di n...   \n",
      "3  kalau bikin konten gimmick menurut lu gimana. ...   \n",
      "4            Mau heran tapi lupa ini di negeri indoðŸ˜‚   \n",
      "\n",
      "                                     cleaned_comment  \n",
      "0  yang niat edukasi sakit yang langka aja malah ...  \n",
      "1  aku pernah dikatain gay gak suka cewek padahal...  \n",
      "2  trending nya joget atau lucu sama kayak negara...  \n",
      "3  kalau bikin konten gimmick turut gimana kayak ...  \n",
      "4                    heran tapi lupa ini negeri indo  \n"
     ]
    }
   ],
   "source": [
    "df['cleaned_comment'] = df['comment'].apply(cleaning)\n",
    "\n",
    "print(df[['comment', 'cleaned_comment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data duplikat: 70\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah data duplikat:\", df['cleaned_comment'].duplicated().sum())\n",
    "\n",
    "df = df.drop_duplicates(subset='cleaned_comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/cleaned_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('./data/cleaned_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.dropna(subset=['cleaned_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sent):\n",
    "    text=str(sent)\n",
    "    # feature extraction\n",
    "    text_feature = feature_bow.transform([text])\n",
    "    # predict\n",
    "    return model_nb.predict(text_feature)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gw yang niat edukasi penyakit yang langka aja ...</td>\n",
       "      <td>yang niat edukasi sakit yang langka aja malah ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku pernah dikatain \"ih gay gak suka cewek, pa...</td>\n",
       "      <td>aku pernah dikatain gay gak suka cewek padahal...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trending nya joget2 atau lucu2 sama kayak di n...</td>\n",
       "      <td>trending nya joget atau lucu sama kayak negara...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kalau bikin konten gimmick menurut lu gimana. ...</td>\n",
       "      <td>kalau bikin konten gimmick turut gimana kayak ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mau heran tapi lupa ini di negeri indoðŸ˜‚</td>\n",
       "      <td>heran tapi lupa ini negeri indo</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0  Gw yang niat edukasi penyakit yang langka aja ...   \n",
       "1  aku pernah dikatain \"ih gay gak suka cewek, pa...   \n",
       "2  trending nya joget2 atau lucu2 sama kayak di n...   \n",
       "3  kalau bikin konten gimmick menurut lu gimana. ...   \n",
       "4            Mau heran tapi lupa ini di negeri indoðŸ˜‚   \n",
       "\n",
       "                                     cleaned_comment predicted_sentiment  \n",
       "0  yang niat edukasi sakit yang langka aja malah ...            negative  \n",
       "1  aku pernah dikatain gay gak suka cewek padahal...            negative  \n",
       "2  trending nya joget atau lucu sama kayak negara...            negative  \n",
       "3  kalau bikin konten gimmick turut gimana kayak ...            negative  \n",
       "4                    heran tapi lupa ini negeri indo             neutral  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['predicted_sentiment'] = clean_df.cleaned_comment.apply(predict_sentiment)\n",
    "\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('./data/comments_predicted_sentiment.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godrick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
